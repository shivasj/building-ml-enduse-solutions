{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import json\n",
    "import datetime\n",
    "import spacy\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Word Frequencies based summarization:\n",
    "A simple and robust method to find the number of times a word has been used in a sentence. Words with higher count are assumed to be more important. Sentences with importent words are slected for the final extractive summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "For this experiment lets pull in the news articles for the last few days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>article_link</th>\n",
       "      <th>article_date</th>\n",
       "      <th>article_title</th>\n",
       "      <th>article_content</th>\n",
       "      <th>article_dts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7c66bfc6f7b115ac9ea1c443d64d9f662a3c7257d06d2a...</td>\n",
       "      <td>npr</td>\n",
       "      <td>https://www.npr.org/2019/12/24/791102803/trump...</td>\n",
       "      <td>December 24, 2019</td>\n",
       "      <td>Trump Downplays Threat Of 'Gift' From North Ko...</td>\n",
       "      <td>President Trump did not seem concerned Tuesday...</td>\n",
       "      <td>1577145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d5e50fa5f13830087bedc86232317ea1790d2417d4d729...</td>\n",
       "      <td>npr</td>\n",
       "      <td>https://www.npr.org/2019/12/23/790747698/newly...</td>\n",
       "      <td>December 23, 2019</td>\n",
       "      <td>Ukraine Emails Fuel Democrats' Call For Impeac...</td>\n",
       "      <td>Party leaders in Congress continued to spar Mo...</td>\n",
       "      <td>1577059200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id source  \\\n",
       "0  7c66bfc6f7b115ac9ea1c443d64d9f662a3c7257d06d2a...    npr   \n",
       "1  d5e50fa5f13830087bedc86232317ea1790d2417d4d729...    npr   \n",
       "\n",
       "                                        article_link       article_date  \\\n",
       "0  https://www.npr.org/2019/12/24/791102803/trump...  December 24, 2019   \n",
       "1  https://www.npr.org/2019/12/23/790747698/newly...  December 23, 2019   \n",
       "\n",
       "                                       article_title  \\\n",
       "0  Trump Downplays Threat Of 'Gift' From North Ko...   \n",
       "1  Ukraine Emails Fuel Democrats' Call For Impeac...   \n",
       "\n",
       "                                     article_content  article_dts  \n",
       "0  President Trump did not seem concerned Tuesday...   1577145600  \n",
       "1  Party leaders in Congress continued to spar Mo...   1577059200  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to database\n",
    "database_url = \"../datastore/app_data.db\"\n",
    "database = sqlite3.connect(database_url)\n",
    "\n",
    "sql = \"select * from articles limit 2\"\n",
    "source_data = pd.read_sql_query(sql, database)\n",
    "\n",
    "print(\"Shape:\",source_data.shape)\n",
    "source_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Article: 2\n",
      "Minimum Article Date: Dec 23 2019\n",
      "Maximum Article Date: Dec 24 2019\n",
      "Minimum Word Count: 276\n",
      "Maximum Word Count: 603\n"
     ]
    }
   ],
   "source": [
    "source_data['word_count'] = source_data['article_content'].str.split().str.len()\n",
    "\n",
    "# View some metrics of data\n",
    "print(\"Number of Article:\",f'{source_data.shape[0]:,}')\n",
    "print(\"Minimum Article Date:\",datetime.datetime.fromtimestamp(min(source_data['article_dts'])).strftime(\"%b %d %Y\"))\n",
    "print(\"Maximum Article Date:\",datetime.datetime.fromtimestamp(max(source_data['article_dts'])).strftime(\"%b %d %Y\"))\n",
    "print(\"Minimum Word Count:\",min(source_data['word_count']))\n",
    "print(\"Maximum Word Count:\",f'{max(source_data[\"word_count\"]):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "The data preprocessing steps that we will follow inorder to feed the data to the model are:\n",
    "- Combine Title with Blog Content\n",
    "- Remove line breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (6, 1)\n"
     ]
    }
   ],
   "source": [
    "# Custom stop words\n",
    "custom_stopwords_file ='../datastore/custom_stopwords.txt'\n",
    "custom_stopwords_df = pd.read_csv(custom_stopwords_file, header=None)\n",
    "print(\"Shape:\",custom_stopwords_df.shape)\n",
    "custom_stopwords = custom_stopwords_df[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities to perfrom data cleaning and preparation\n",
    "\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "# function to remove stopwords\n",
    "def remove_stopwords(rev):\n",
    "    rev_new = \" \".join([i for i in rev if i not in stop_words])\n",
    "    return rev_new\n",
    "\n",
    "def remove_custom_stopwords(rev):\n",
    "    rev_new = \" \".join([i for i in rev if i not in custom_stopwords])\n",
    "    return rev_new\n",
    "\n",
    "def lemmatization(texts, tags=['NOUN', 'ADJ']):\n",
    "    output = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        output.append([token.lemma_ for token in doc if token.pos_ in tags])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trump downplays threat gift north korea maybe beautiful vase president trump seem concerned tuesday asked threat christmas present north korea u.s. roll back economic sanctions country end year. maybe nice present trump told reporters event mar lago resort florida. maybe present sends beautiful vase opposed missile test. pyongyang imposed end year deadline concessions u.s. earlier month trump administration given sign plans give pressure campaign. u.s. wants north korea give entire nuclear arsenal removing sanctions. dealing north korea nuclear ambitions one trump top foreign policy priorities held series meetings north korea kim jong un try negotiate solution. world north korea promises christmas surprise. options unclear exactly christmas gift north korea threatening npr geoff brumfiel laid options monday including launching rocket payload space conducting underground nuclear test testing long range missile capable reaching united states territories. tuesday trump elaborate u.s. would respond north korea conduct another missile test. find surprise deal successfully. let see happens. everybody got surprises let see happens trump said. handle come along.',\n",
       " 'ukraine emails fuel democrats call impeachment trial witnesses party leaders congress continued spar monday details impending impeachment trial senate newly released emails giving ammunition democrats requests new witnesses. emails released late friday center public integrity heavily redacted democrats jumped one particular bolster argument know saga president trump withholding military aid ukraine exchange political investigations. message hold senior official office management budget michael duffey sent less two hours trump got phone ukrainian president volodymyr zelenskiy july requested matter kept quiet. duffey said halt based guidance received light administration plan review assistance ukraine. given sensitive nature request appreciate keeping information closely held need know execute direction duffey wrote. newly released emails show government officials grappling issues raised trump administration decision withhold aid ukraine. huge anxiety inside government aid hold unwise illegal center public integrity r. jeffrey smith said npr morning edition. law compels president government officials spend money appropriated congress. trump impeachment inquiry trump impeachment inquiry guide key people facts documents senate minority leader chuck schumer n.y. called duffey email explosive held copy press conference sunday. trying ratchet pressure senate majority leader mitch mcconnell r ky. agree call new witnesses trial begins senate. trial witnesses documents sham trial schumer said sign democrats already laying groundwork question legitimacy senate trial. hear witnesses get documents american people correctly assume blocking testimony aiding abetting cover schumer said. plain simple. senate trial begin house transferred articles impeachment named impeachment managers house speaker nancy pelosi calif. says putting details senate trial look like. republican controlled senate expected sufficient votes acquit president leaving democrats using ability stall transfer leverage. mcconnell laughed asked pelosi strategy fox news monday morning. apparently trying tell us run trial mcconnell said. trump impeachment inquiry mcconnell impartial impeachment mcconnell completely ruled calling new witnesses senate trial alluded fact consider impartial juror said earlier month chance trump removed office chamber. made clear last week feels democrats wanted investigation wanted compel documents testimony already held impeachment vote house. house chose road mcconnell said last week. duty investigate. duty meet high bar undoing national election.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge title with content\n",
    "source_data['text'] = source_data['article_title'] + \" \" + source_data[\"article_content\"]\n",
    "\n",
    "# Convert column to str\n",
    "source_data['text'] = source_data['text'].apply(str)\n",
    "\n",
    "# Replace line breaks\n",
    "article_text = source_data['text'].str.replace(\"\\n\", \" \")\n",
    "\n",
    "# remove unwanted characters and symbols\n",
    "article_text = article_text.str.replace(\"[^a-zA-Z#.]\", \" \")\n",
    "\n",
    "# Remove double spaces\n",
    "article_text = article_text.str.replace(\"  \", \" \")\n",
    "article_text = article_text.str.replace(\"  \", \" \")\n",
    "article_text = article_text.str.replace(\"  \", \" \")\n",
    "\n",
    "# make entire text lowercase\n",
    "article_text = [r.lower() for r in article_text]\n",
    "\n",
    "# remove stopwords from the text\n",
    "article_text = [remove_stopwords(r.split()) for r in article_text]\n",
    "\n",
    "# Remove custom stopwords\n",
    "article_text = [remove_custom_stopwords(r.split()) for r in article_text]\n",
    "\n",
    "# # Tokenize\n",
    "# tokenized_text = pd.Series(article_text).apply(lambda x: x.split())\n",
    "# # Lemmatize\n",
    "# tokenized_text = lemmatization(tokenized_text)\n",
    "\n",
    "# # Remove custom stopwords\n",
    "# tokenized_text = remove_custom_stopwords(tokenized_text)\n",
    "\n",
    "# tokenized_text\n",
    "article_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_dictionary_table(text_string) -> dict:\n",
    "   \n",
    "    #removing stop words\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    words = word_tokenize(text_string)\n",
    "    \n",
    "    #reducing words to their root form\n",
    "    stem = PorterStemmer()\n",
    "    \n",
    "    #creating dictionary for the word frequency table\n",
    "    frequency_table = dict()\n",
    "    for wd in words:\n",
    "        wd = stem.stem(wd)\n",
    "        if wd in stop_words:\n",
    "            continue\n",
    "        if wd in frequency_table:\n",
    "            frequency_table[wd] += 1\n",
    "        else:\n",
    "            frequency_table[wd] = 1\n",
    "\n",
    "    return frequency_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
